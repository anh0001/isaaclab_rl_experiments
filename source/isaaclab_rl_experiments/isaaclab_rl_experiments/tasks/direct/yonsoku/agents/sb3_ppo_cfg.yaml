# SB3 PPO Configuration for Yonsoku
seed: 42

n_timesteps: !!float 1e7
policy: 'MlpPolicy'
n_steps: 24
batch_size: 8192
gae_lambda: 0.95
gamma: 0.99
n_epochs: 4
ent_coef: 0.01
learning_rate: !!float 3e-4
clip_range: !!float 0.2
policy_kwargs: "dict(
                  activation_fn=nn.ELU,
                  net_arch=[512, 256, 128],
                  squash_output=False,
                )"
vf_coef: 1.0
max_grad_norm: 1.0
device: "cuda:0"
normalize_input: True
normalize_value: True
clip_obs: 5.0